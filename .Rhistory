themis::step_rose(sum_lmb)
# apply recipe
set.seed(123)
xgb_juiced <- xgb_rec %>% prep() %>% juice()
xgb_rec <- recipe(sum_lmb ~ ., data = xgb_train)
# apply recipe
set.seed(123)
xgb_juiced <- xgb_rec %>% prep() %>% juice()
# set up folds; use bootstraps because of small sample size
set.seed(234)
xgb_folds <- vfold_cv(xgb_juiced, strata = sasq)
xgb_folds <- vfold_cv(xgb_juiced)
# model tuning
xgb_spec <- boost_tree(
trees = 3000,
tree_depth = tune(),
min_n = tune(),
loss_reduction = tune(),
sample_size = tune(),
mtry = tune(),
learn_rate = tune()
) %>%
set_engine("xgboost") %>%
set_mode("classification")
# tuning grid
xgb_grid <- grid_latin_hypercube(
tree_depth(),
min_n(),
loss_reduction(),
sample_size = sample_prop(),
finalize(mtry(), xgb_train),
learn_rate(),
size = 40
)
# create a workflow
xgb_wf <- workflow() %>%
add_formula(sum_lmb ~ .) %>%
add_model(xgb_spec)
set.seed(123)
# fit the model
xgb_res <- tune_grid(
xgb_wf,
resamples = xgb_folds,
grid = xgb_grid,
control = control_grid(save_pred = TRUE, verbose = TRUE)
)
# fit the model
xgb_res <- tune_grid(
xgb_wf,
resamples = xgb_folds,
grid = xgb_grid,
control = control_grid(save_pred = TRUE, verbose = TRUE)
)
# model tuning
xgb_spec <- boost_tree(
trees = 3000,
tree_depth = tune(),
min_n = tune(),
loss_reduction = tune(),
sample_size = tune(),
mtry = tune(),
learn_rate = tune()
) %>%
set_engine("xgboost") %>%
set_mode("regression")
# tuning grid
xgb_grid <- grid_latin_hypercube(
tree_depth(),
min_n(),
loss_reduction(),
sample_size = sample_prop(),
finalize(mtry(), xgb_train),
learn_rate(),
size = 40
)
# create a workflow
xgb_wf <- workflow() %>%
add_formula(sum_lmb ~ .) %>%
add_model(xgb_spec)
set.seed(123)
# fit the model
xgb_res <- tune_grid(
xgb_wf,
resamples = xgb_folds,
grid = xgb_grid,
control = control_grid(save_pred = TRUE, verbose = TRUE)
)
# check metrics
xgb_res %>%
collect_metrics()
# check metrics
xgb_res %>%
collect_metrics() %>%
filter(.metric == "rmse") %>%
select(mean, mtry:sample_size) %>%
pivot_longer(mtry:sample_size,
values_to = "value",
names_to = "parameter"
) %>%
ggplot(aes(value, mean, color = parameter)) +
geom_point(alpha = 0.8, show.legend = FALSE) +
facet_wrap(~parameter, scales = "free_x") +
labs(x = NULL, y = "rmse")
# best models
show_best(xgb_res, "roc_auc")
# best models
show_best(xgb_res, "rmse")
best_auc <- select_best(xgb_res, "rmse")
best_auc
# create workflow with best model
final_xgb <- finalize_workflow(
xgb_wf,
best_auc
)
final_xgb
# check for variable importance
library(vip)
final_fit_xgb <- final_xgb %>%
fit(data = xgb_juiced)
final_fit_xgb  %>%
extract_fit_parsnip() %>%
vip(geom = "col")
final_fit_xgb %>%
predict(xgb_juiced) %>%
bind_cols(xgb_juiced)
final_fit_xgb %>%
predict(xgb_juiced) %>%
bind_cols(xgb_juiced) %>%
ggplot() +
geom_point(aes(x = sum_lmb, y = .pred))
final_fit_xgb %>%
predict(xgb_juiced) %>%
bind_cols(xgb_juiced) %>%
ggplot() +
geom_point(aes(x = sum_lmb, y = .pred)) +
geom_abline()
final_fit_xgb %>%
predict(xgb_juiced) %>%
bind_cols(xgb_juiced) %>%
ggplot() +
geom_point(aes(x = sum_lmb, y = .pred)) +
geom_abline(lty = 2, color = "red", size = 1.5)
final_fit_xgb %>% collect_metrics()
rlang::last_error()
final_xgb %>% collect_metrics()
final_xgb %>% last_fit(xgb_split)
final_xgb %>% last_fit(xgb_split) %>% collect_metrics()
rf_res %>%
collect_metrics()
results_test %>%
mutate(train = "testing") %>%
bind_rows(results_train %>%
mutate(train = "training")) %>%
ggplot(aes(truth, .pred, color = model)) +
geom_abline(lty = 2, color = "gray80", size = 1.5) +
geom_point(alpha = 0.5) +
facet_wrap(~train) +
labs(
x = "Truth",
y = "Predicted value",
color = "Type of model"
) +
xlim(0, 20) +
ylim(0, 20) +
theme_bw()
splits <- initial_split(lmb_fitting)
training_data <- training(splits)
testing_data <- testing(splits)
set.seed(234)
folds <- vfold_cv(training_data)
cores <- parallel::detectCores()
set.seed(345)
rec <- recipe(sum_lmb ~ ., data = training_data) %>%
# update_role(regioncode, subregion, sampledate, segment_number, new_role = "ID") %>%
#step_poly(all_numeric_predictors(), degree = 3) %>%
step_dummy(all_nominal_predictors()) %>%
step_center(all_predictors())
svm_spec <-
svm_rbf() %>%
set_mode("regression") %>%
set_engine("kernlab")
wf <-
workflow() %>%
add_recipe(rec)
doParallel::registerDoParallel()
svm_results <-
wf %>%
add_model(svm_spec) %>%
fit_resamples(
resamples = folds,
control = control_resamples(save_pred = TRUE, verbose = TRUE)
)
splits <- initial_split(lmb_fitting)
training_data <- training(splits)
testing_data <- testing(splits)
set.seed(234)
folds <- vfold_cv(training_data)
cores <- parallel::detectCores()
set.seed(345)
rec <- recipe(sum_lmb ~ ., data = training_data) %>%
# update_role(regioncode, subregion, sampledate, segment_number, new_role = "ID") %>%
#step_poly(all_numeric_predictors(), degree = 3) %>%
step_dummy(all_nominal_predictors()) %>%
step_center(all_predictors())
svm_spec <-
svm_rbf() %>%
set_mode("regression") %>%
set_engine("kernlab")
wf <-
workflow() %>%
add_recipe(rec)
doParallel::registerDoParallel()
svm_results <-
wf %>%
add_model(svm_spec) %>%
fit_resamples(
resamples = folds,
control = control_resamples(save_pred = TRUE, verbose = TRUE)
)
svm_results %>%
collect_metrics()
svm_results %>%
conf_mat_resampled()
set.seed(123)
set.seed(123)
split <- initial_split(lmb_fitting)
train <- training(split)
test <- testing(split)
lm_spec <- linear_reg() %>%
set_engine("lm")
lm_fit <- lm_spec %>%
fit(sum_lmb ~ ., data = train)
rf_spec <- rand_forest(mode = "regression") %>%
set_engine("ranger")
rf_fit <- rf_spec %>%
fit(sum_lmb ~ ., data = train)
rf_fit
results_train <- lm_fit %>%
predict(new_data = train) %>%
mutate(
truth = train$sum_lmb,
model = "lm"
) %>%
bind_rows(rf_fit %>%
predict(new_data = train) %>%
mutate(
truth = train$sum_lmb,
model = "rf"
))
results_test <- lm_fit %>%
predict(new_data = test) %>%
mutate(
truth = test$sum_lmb,
model = "lm"
) %>%
bind_rows(rf_fit %>%
predict(new_data = test) %>%
mutate(
truth = test$sum_lmb,
model = "rf"
))
results_train %>%
group_by(model) %>%
rmse(truth = truth, estimate = .pred)
results_test %>%
group_by(model) %>%
rmse(truth = truth, estimate = .pred)
folds <- vfold_cv(train)
wf <- workflow() %>%
add_model(rf_spec)
rf_res <- fit_resamples(
workflow(sum_lmb ~ ., rf_spec),
folds,
control = control_resamples(save_pred = TRUE)
)
rf_res %>%
collect_metrics()
library(tidymodels)
splits <- initial_split(lmb)
training_data <- training(splits)
testing_data <- testing(splits)
cores <- parallel::detectCores()
spec <- rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%
# set_engine("ranger", num.threads = cores) %>%
set_engine("ranger") %>%
set_mode("regression")
rec <- recipe(sum_lmb ~ ., data = training_data) %>%
update_role(regioncode, subregion, sampledate, segment_number, new_role = "ID") %>%
step_dummy(all_nominal_predictors())
data_prep <- prep(rec)
juiced <- juice(data_prep)
tune_wf <- workflow() %>%
add_recipe(rec) %>%
add_model(spec)
set.seed(234)
folds <- vfold_cv(training_data)
set.seed(345)
doParallel::registerDoParallel()
tune_res <- tune_grid(
tune_wf,
resamples = folds,
grid = 20
)
tune_res
tune_res %>%
collect_metrics() %>%
filter(.metric == "rmse") %>%
select(mean, min_n, mtry) %>%
pivot_longer(min_n:mtry,
values_to = "value",
names_to = "parameter"
) %>%
ggplot(aes(value, mean, color = parameter)) +
geom_point(show.legend = FALSE) +
facet_wrap(~parameter, scales = "free_x") +
labs(x = NULL, y = "rmse")
rf_grid <- grid_regular(
mtry(range = c(5, 15)),
min_n(range = c(10, 20)),
levels = 5
)
rf_grid
set.seed(456)
doParallel::registerDoParallel()
regular_res <- tune_grid(
tune_wf,
resamples = folds,
grid = rf_grid
)
regular_res
best <- select_best(regular_res, "rmse")
best
final_rf <- finalize_model(
spec,
best
)
final_rf
library(vip)
final_rf %>%
set_engine("ranger", importance = "permutation") %>%
fit(sum_lmb ~ .,
data = juiced %>% select(-c(regioncode:starttime, segment_number))
) %>%
vip(geom = "point")
final_rf %>%
set_engine("ranger", importance = "permutation") %>%
fit(sum_lmb ~ .,
data = juiced %>% select(-c(regioncode:starttime, segment_number))
) %>%
vip(geom = "bar")
final_rf %>%
set_engine("ranger", importance = "permutation") %>%
fit(sum_lmb ~ .,
data = juiced %>% select(-c(regioncode:starttime, segment_number))
) %>%
vip(geom = "col")
final_wf <- workflow() %>%
add_recipe(rec) %>%
add_model(final_rf)
final_res <- final_wf %>%
last_fit(splits)
final_res %>%
collect_metrics()
final_res %>%
collect_predictions() %>%
ggplot(aes(x = sum_lmb, y = .pred)) +
geom_abline(lty = 2, color = "black", size = 1.5) +
geom_point(alpha = 0.5, color = "dodgerblue") +
theme_bw() +
xlab("observed number of fish") +
ylab("predicted number of fish")
tune_res
tune_res %>% collect_metrics()
tune_res %>%
collect_metrics() %>%
filter(.metric == "rmse")
tune_res %>% select_best()
best
regular_res
rf_grid
rf_grid <- grid_regular(
mtry(range = c(5, 15)),
min_n(range = c(10, 20)),
levels = 10
)
rf_grid
rf_grid <- grid_regular(
mtry(range = c(5, 15)),
min_n(range = c(10, 20)),
levels = 10
)
set.seed(456)
doParallel::registerDoParallel()
regular_res <- tune_grid(
tune_wf,
resamples = folds,
grid = rf_grid
)
regular_res
best <- select_best(regular_res, "rmse")
best
final_rf <- finalize_model(
spec,
best
)
final_rf
library(vip)
final_rf %>%
set_engine("ranger", importance = "permutation") %>%
fit(sum_lmb ~ .,
data = juiced %>% select(-c(regioncode:starttime, segment_number))
) %>%
vip(geom = "col")
final_wf <- workflow() %>%
add_recipe(rec) %>%
add_model(final_rf)
final_res <- final_wf %>%
last_fit(splits)
final_res %>%
collect_metrics()
regular_res
best <- select_best(regular_res, "rmse")
best
tune_res
best <- select_best(tune_res, "rmse")
best
final_rf <- finalize_model(
spec,
best
)
final_wf <- workflow() %>%
add_recipe(rec) %>%
add_model(final_rf)
final_res <- final_wf %>%
last_fit(splits)
final_res %>%
collect_metrics()
final_xgb
final_xgb %>% last_fit(xgb_split)
final_xgb %>% last_fit(xgb_split) %>% collect_metrics()
final_fit_xgb %>%
predict(xgb_test) %>%
bind_cols(xgb_test) %>%
ggplot() +
geom_point(aes(x = sum_lmb, y = .pred)) +
geom_abline(lty = 2, color = "red", size = 1.5)
lmb %>% pull(sum_lmb)
lmb %>% pull(sum_lmb) %>% hist()
lmb %>% pull(sum_lmb) %>% log() %>%  hist()
library(poissonreg)
poisson_spec <- poisson_reg() %>%
set_engine("zeroinfl")
vars <- lmb_fitting %>% names()
dep <- "sum_lmb"
ind <- vars[vars != dep]
formula <- formula(paste(dep, " ~ ", paste(ind, collapse = " + ")))
wf <-
workflow() %>%
add_variables(outcomes = dep, predictors = ind) %>%
add_model(poisson_spec, formula = formula)
doParallel::registerDoParallel()
poisson_results <-
wf %>%
fit_resamples(
resamples = folds,
control = control_resamples(save_pred = TRUE, verbose = TRUE)
)
library(poissonreg)
poisson_spec <- poisson_reg() %>%
set_engine("zeroinfl")
vars <- lmb_fitting %>% names()
dep <- "sum_lmb"
ind <- vars[vars != dep]
formula <- formula(paste(dep, " ~ ", paste(ind, collapse = " + ")))
wf <-
workflow() %>%
add_variables(outcomes = dep, predictors = ind) %>%
add_model(poisson_spec, formula = formula)
doParallel::registerDoParallel()
poisson_results <-
wf %>%
fit_resamples(
resamples = folds,
control = control_resamples(save_pred = TRUE, verbose = TRUE)
)
poisson_results %>% collect_metrics()
poisson_fit <-
wf %>%
last_fit(split)
poisson_fit$.workflow[[1]] %>%
tidy() %>%
filter(p.value  <= 0.05)
augment(poisson_results) %>%
ggplot(aes(x = sum_lmb, y = .pred)) +
geom_abline(lty = 2, color = "black", size = 1.5) +
geom_point(alpha = 0.5, color = "dodgerblue") +
theme_bw() +
# xlim(0,15) +
# ylim(0,15) +
xlab("observed number of fish") +
ylab("predicted number of fish")
poisson_fit %>% collect_metrics()
poisson_results %>% collect_metrics()
poisson_results
poisson_results %>% show_notes()
poisson_fit <-
wf %>%
last_fit(split)
poisson_fit <-
wf %>%
last_fit(split)
poisson_fit
